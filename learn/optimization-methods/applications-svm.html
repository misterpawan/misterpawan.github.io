<!DOCTYPE html>
<html lang="en" class="scroll-smooth">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Support Vector Machines | Optimization Applications</title>

    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- AOS Animation -->
    <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">
    <script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>

    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['\\(', '\\)']],
                displayMath: [['\\[', '\\]']],
                tags: 'ams'
            }
        };
    </script>

    <style>
        .glass {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .dark .glass {
            background: rgba(17, 24, 39, 0.95);
        }

        .gradient-bg {
            background: linear-gradient(135deg, #f43f5e 0%, #e11d48 100%);
        }

        .definition-box {
            border-left: 4px solid #3b82f6;
            background: linear-gradient(to right, #eff6ff, #ffffff);
            padding: 1.5rem;
            border-radius: 0.75rem;
            margin: 1rem 0;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }

        .example-box {
            border-left: 4px solid #f59e0b;
            background: linear-gradient(to right, #fffbeb, #ffffff);
            padding: 1.5rem;
            border-radius: 0.75rem;
            margin: 1rem 0;
        }

        #progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: linear-gradient(90deg, #f43f5e 0%, #e11d48 100%);
            width: 0%;
            z-index: 9999;
            transition: width 0.2s;
        }
    </style>
</head>

<body class="bg-gray-50 dark:bg-gray-900 text-gray-900 dark:text-gray-100">
    <div id="progress-bar"></div>

    <!-- Navigation -->
    <nav class="glass sticky top-0 z-50 p-4">
        <div class="container mx-auto flex justify-between items-center">
            <a href="index.html" class="text-xl font-bold gradient-bg bg-clip-text text-transparent">
                ‚Üê Optimization Methods
            </a>
            <span class="text-sm font-semibold">Chapter 8: Applications</span>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="gradient-bg text-white py-20" data-aos="fade-down">
        <div class="container mx-auto px-4 text-center">
            <div class="inline-block mb-4 p-3 bg-white/20 rounded-full">
                <span class="text-6xl">‚öîÔ∏è</span>
            </div>
            <h1 class="text-5xl font-bold mb-4">Support Vector Machines</h1>
            <p class="text-xl mb-6 max-w-3xl mx-auto">
                Maximizing the margin with convex quadratic programming.
            </p>
        </div>
    </section>

    <!-- Main Content -->
    <main class="container mx-auto px-4 py-12 max-w-5xl">

        <!-- 1. Motivation -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-blue-100 text-blue-700 p-3 rounded-xl text-2xl">üéØ</span>
                <h2 class="text-3xl font-bold">1. Motivation</h2>
            </div>

            <div class="definition-box">
                <h4 class="font-bold text-lg mb-2">The Problem</h4>
                <p>Find a <strong>linear decision surface (Hyperplane)</strong> that can separate two classes and has
                    the <strong>largest distance (margin)</strong> between the border line classes.</p>
                <ul class="list-disc list-inside mt-2 text-gray-700">
                    <li><strong>Support Vectors:</strong> The data points on the boundary.</li>
                    <li><strong>Margin:</strong> The largest gap between the classes.</li>
                </ul>
            </div>

            <p class="mb-4">If the data is linearly separable, there are infinite hyperplanes that can separate the
                classes. SVM finds the "best" one‚Äîthe one that maximizes the margin.</p>
        </section>

        <!-- 2. Primal Formulation -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-purple-100 text-purple-700 p-3 rounded-xl text-2xl">üìê</span>
                <h2 class="text-3xl font-bold">2. Primal Formulation</h2>
            </div>

            <p class="mb-4">Let the hyperplane be defined by \( w \cdot x + b = 0 \). We want to classify data points \(
                (x_i, y_i) \) where \( y_i \in \{+1, -1\} \).</p>

            <div class="bg-white p-6 rounded-xl shadow-sm border border-gray-100 mb-6">
                <h4 class="font-bold text-lg mb-3">Geometric Insight</h4>
                <p class="mb-2">We scale \( w \) and \( b \) such that the support vectors lie on the hyperplanes:</p>
                \[ w \cdot x + b = 1 \quad \text{and} \quad w \cdot x + b = -1 \]
                <p class="mt-2">The distance (margin) between these planes is \( \frac{2}{\|w\|} \). To maximize the
                    margin, we <strong>minimize \( \|w\|^2 \)</strong>.</p>
            </div>

            <div class="definition-box">
                <h4 class="font-bold text-lg mb-2">SVM Primal Optimization Problem</h4>
                \[ \begin{aligned}
                & \text{minimize} && \frac{1}{2} \|w\|^2 \\
                & \text{subject to} && y_i (w \cdot x_i + b) \geq 1, \quad i=1,\dots,m
                \end{aligned} \]
            </div>
            <p class="text-sm text-gray-600 mt-2">This is a <strong>Convex Quadratic Programming (QP)</strong> problem.
            </p>
        </section>

        <!-- 3. Dual Formulation -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-green-100 text-green-700 p-3 rounded-xl text-2xl">üîÑ</span>
                <h2 class="text-3xl font-bold">3. Dual Formulation</h2>
            </div>

            <p class="mb-4">By forming the Lagrangian and setting derivatives to zero, we obtain the dual problem. This
                is useful when the number of features is large compared to the number of samples.</p>

            <div class="definition-box">
                <h4 class="font-bold text-lg mb-2">SVM Dual Optimization Problem</h4>
                \[ \begin{aligned}
                & \text{maximize} && \sum_{i=1}^m \lambda_i - \frac{1}{2} \sum_{i,j=1}^m \lambda_i \lambda_j y_i y_j
                (x_i \cdot x_j) \\
                & \text{subject to} && \lambda_i \geq 0, \quad i=1,\dots,m \\
                & && \sum_{i=1}^m \lambda_i y_i = 0
                \end{aligned} \]
            </div>

            <div class="bg-yellow-50 p-4 rounded-lg mt-4 border border-yellow-200">
                <h5 class="font-bold text-yellow-800">Key Observation</h5>
                <p class="text-sm text-yellow-900">The dual problem depends only on the <strong>dot products</strong> \(
                    x_i \cdot x_j \). This allows us to use the <strong>Kernel Trick</strong> to handle non-linearly
                    separable data by implicitly mapping it to a higher-dimensional space!</p>
            </div>
        </section>

        <!-- 4. Soft-Margin SVM -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-red-100 text-red-700 p-3 rounded-xl text-2xl">üå´Ô∏è</span>
                <h2 class="text-3xl font-bold">4. Soft-Margin SVM</h2>
            </div>

            <p class="mb-4">Real-world data is often noisy and not perfectly separable. We introduce <strong>slack
                    variables</strong> \( \xi_i \) to allow some misclassification, but penalize them with a parameter
                \( C \).</p>

            <div class="grid md:grid-cols-2 gap-6">
                <div class="bg-white p-6 rounded-xl shadow-sm">
                    <h4 class="font-bold text-lg mb-2">Primal Soft-Margin</h4>
                    \[ \min \frac{1}{2} \|w\|^2 + C \sum_{i=1}^m \xi_i \]
                    <p class="text-sm mt-2">Subject to \( y_i(w \cdot x_i + b) \geq 1 - \xi_i \)</p>
                </div>
                <div class="bg-white p-6 rounded-xl shadow-sm">
                    <h4 class="font-bold text-lg mb-2">Dual Soft-Margin</h4>
                    <p class="text-sm mb-2">Same objective as standard dual, but with box constraints:</p>
                    \[ 0 \leq \lambda_i \leq C \]
                </div>
            </div>
        </section>

        <!-- 5. The Kernel Trick -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-indigo-100 text-indigo-700 p-3 rounded-xl text-2xl">‚ú®</span>
                <h2 class="text-3xl font-bold">5. The Kernel Trick</h2>
            </div>

            <p class="mb-4">What if the data is <strong>not linearly separable</strong>? We can map the data to a
                higher-dimensional feature space where it <em>is</em> separable.</p>

            <div class="bg-white p-6 rounded-xl shadow-sm border border-gray-100 mb-6">
                <h4 class="font-bold text-lg mb-3">Implicit Mapping</h4>
                <p class="mb-2">Instead of computing the mapping \( \Phi(x) \) explicitly (which can be expensive or
                    infinite-dimensional), we use a <strong>Kernel Function</strong> \( K(x_i, x_j) \) that computes the
                    dot product in the feature space:</p>
                \[ K(x_i, x_j) = \Phi(x_i) \cdot \Phi(x_j) \]
                <p class="mt-2 text-sm text-gray-600">The dual formulation depends only on dot products, so we simply
                    replace \( x_i \cdot x_j \) with \( K(x_i, x_j) \).</p>
            </div>

            <h4 class="font-bold text-lg mb-4">Popular Kernels</h4>
            <div class="grid md:grid-cols-2 gap-4">
                <div class="bg-indigo-50 p-4 rounded-lg">
                    <p class="font-bold text-indigo-900">Polynomial Kernel</p>
                    <p class="font-mono text-sm mt-1">\( K(x, z) = (x \cdot z + c)^d \)</p>
                </div>
                <div class="bg-indigo-50 p-4 rounded-lg">
                    <p class="font-bold text-indigo-900">Gaussian (RBF) Kernel</p>
                    <p class="font-mono text-sm mt-1">\( K(x, z) = \exp(-\gamma \|x - z\|^2) \)</p>
                </div>
            </div>
        </section>

        <!-- 6. Unconstrained SVM (Hinge Loss) -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-orange-100 text-orange-700 p-3 rounded-xl text-2xl">üìâ</span>
                <h2 class="text-3xl font-bold">6. Unconstrained Form</h2>
            </div>

            <p class="mb-4">We can rewrite the Soft-Margin SVM as an unconstrained optimization problem involving the
                <strong>Hinge Loss</strong>.</p>

            <div class="definition-box">
                <h4 class="font-bold text-lg mb-2">Loss + Penalty</h4>
                \[ \text{minimize} \quad \sum_{i=1}^m \max(0, 1 - y_i f(x_i)) + \lambda \|w\|^2 \]
                <ul class="list-disc list-inside mt-2 text-gray-700 text-sm">
                    <li><strong>Loss:</strong> \( \max(0, 1 - y_i f(x_i)) \) (Hinge Loss) - penalizes misclassification.
                    </li>
                    <li><strong>Penalty:</strong> \( \lambda \|w\|^2 \) - regularization term (inverse of \( C \)).</li>
                </ul>
            </div>
        </section>

        <!-- 7. SVM Regression (SVR) -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-teal-100 text-teal-700 p-3 rounded-xl text-2xl">üìä</span>
                <h2 class="text-3xl font-bold">7. SVM Regression (SVR)</h2>
            </div>

            <p class="mb-4">SVM can also be used for regression! The goal is to find a function that fits the data
                within an \( \epsilon \)-margin.</p>

            <div class="bg-white p-6 rounded-xl shadow-sm border border-gray-100">
                <h4 class="font-bold text-lg mb-2">Optimization Model</h4>
                \[ \begin{aligned}
                & \text{minimize} && \frac{1}{2} \|w\|^2 \\
                & \text{subject to} && |y_i - (w \cdot x_i + b)| \leq \epsilon
                \end{aligned} \]
                <p class="text-sm text-gray-600 mt-2">We ignore errors smaller than \( \epsilon \), creating a "tube"
                    around the regression line.</p>
            </div>
        </section>

        <!-- 8. Solving Dual Kernel SVM -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-gray-100 text-gray-700 p-3 rounded-xl text-2xl">‚öôÔ∏è</span>
                <h2 class="text-3xl font-bold">8. Solving via QP</h2>
            </div>

            <p class="mb-4">To solve the Dual Kernel SVM, we map it to a standard Quadratic Programming (QP) solver.</p>

            <div class="bg-gray-50 p-6 rounded-xl font-mono text-sm overflow-x-auto">
                <strong>Standard QP:</strong> min (1/2)x·µÄPx + q·µÄx s.t. Gx ‚â§ h, Ax = b <br><br>
                <strong>SVM Mapping:</strong> <br>
                - Variable x = [Œª‚ÇÅ, ..., Œª‚Çò]·µÄ <br>
                - Matrix P·µ¢‚±º = y·µ¢y‚±º K(x·µ¢, x‚±º) <br>
                - Vector q = [-1, ..., -1]·µÄ <br>
                - Equality: Œ£ Œª·µ¢y·µ¢ = 0 (A = y·µÄ, b = 0) <br>
                - Bounds: 0 ‚â§ Œª·µ¢ ‚â§ C
            </div>
        </section>

        <!-- 9. Interactive Quiz -->
        <section class="glass p-8 rounded-3xl mb-8" data-aos="fade-up">
            <div class="flex items-center gap-3 mb-6">
                <span class="bg-yellow-100 text-yellow-700 p-3 rounded-xl text-2xl">‚úçÔ∏è</span>
                <h2 class="text-3xl font-bold">9. Test Your Understanding</h2>
            </div>

            <div class="space-y-6">
                <!-- Quiz 1 -->
                <div class="bg-white p-6 rounded-xl shadow-sm">
                    <h4 class="font-bold mb-3">1. What is the main advantage of the Kernel Trick?</h4>
                    <div class="flex flex-col gap-2">
                        <button onclick="alert('Incorrect. It actually increases the effective dimensionality.')"
                            class="p-3 text-left bg-gray-50 hover:bg-red-100 rounded transition">It reduces the
                            dimensionality of the data.</button>
                        <button
                            onclick="alert('Correct! It allows us to operate in a high-dimensional space without explicitly computing the coordinates, using only dot products.')"
                            class="p-3 text-left bg-gray-50 hover:bg-green-100 rounded transition">It avoids explicit
                            computation of high-dimensional features.</button>
                    </div>
                </div>

                <!-- Quiz 2 -->
                <div class="bg-white p-6 rounded-xl shadow-sm">
                    <h4 class="font-bold mb-3">2. In Hinge Loss, when is the loss zero?</h4>
                    <div class="flex flex-col gap-2">
                        <button
                            onclick="alert('Correct! If the point is correctly classified and outside the margin (y*f(x) >= 1), the loss is max(0, negative) = 0.')"
                            class="p-3 text-left bg-gray-50 hover:bg-green-100 rounded transition">When the point is
                            correctly classified with a margin of at least 1.</button>
                        <button
                            onclick="alert('Incorrect. Even if correctly classified, if it is within the margin (0 < y*f(x) < 1), there is a loss.')"
                            class="p-3 text-left bg-gray-50 hover:bg-red-100 rounded transition">Whenever the point is
                            correctly classified (y*f(x) > 0).</button>
                    </div>
                </div>
            </div>
        </section>

        <!-- Chapter Navigation -->
        <div class="flex justify-between mt-12" data-aos="fade-up">
            <a href="applications-recommender-systems.html"
                class="group flex items-center gap-3 px-6 py-3 bg-white dark:bg-gray-800 rounded-xl shadow-sm hover:shadow-md transition border border-gray-100 dark:border-gray-700">
                <span class="text-2xl group-hover:-translate-x-1 transition">‚Üê</span>
                <div class="text-left">
                    <p class="text-xs text-gray-500 uppercase font-semibold">Previous Chapter</p>
                    <p class="font-bold text-gray-900 dark:text-gray-100 group-hover:text-pink-600 transition">
                        Recommender Systems</p>
                </div>
            </a>
            <!-- Next chapter placeholder -->
            <button
                class="group flex items-center gap-3 px-6 py-3 bg-gray-100 rounded-xl cursor-not-allowed opacity-50">
                <div class="text-right">
                    <p class="text-xs text-gray-500 uppercase font-semibold">Next Chapter</p>
                    <p class="font-bold text-gray-900">Coming Soon</p>
                </div>
                <span class="text-2xl">‚Üí</span>
            </button>
        </div>

    </main>

    <!-- Footer -->
    <footer class="glass p-6 mt-12">
        <div class="container mx-auto text-center text-gray-600 dark:text-gray-400">
            <p>¬© 2024 Optimization Methods Course - Chapter 8</p>
        </div>
    </footer>

    <script>
        AOS.init({
            duration: 800,
            once: true,
            offset: 100
        });

        // Progress bar
        window.addEventListener('scroll', () => {
            const windowHeight = window.innerHeight;
            const documentHeight = document.documentElement.scrollHeight - windowHeight;
            const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
            const progress = (scrollTop / documentHeight) * 100;
            document.getElementById('progress-bar').style.width = progress + '%';
        });
    </script>
</body>

</html>